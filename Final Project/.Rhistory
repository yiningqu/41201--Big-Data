# Convert the age column to numeric
data$x633 <- as.numeric(data$x633)
# Define the response variable and the treatment
health <- data$health
age <- data$x633
# Plot the distribution of Age using a histogram
ggplot(data, aes(x = x633)) +
geom_histogram(binwidth = 5, fill = "blue", color = "black") +
xlab("Age") +
ylab("Count") +
ggtitle("Distribution of Respondents' Age") +
theme_minimal() +  # Apply a minimal theme for a cleaner look
theme(
plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
axis.title.x = element_text(size = 12, face = "bold"),
axis.title.y = element_text(size = 12, face = "bold")
)
# Function to perform multinomial logistic regression and return p-values
margreg <- function(i) {
model <- multinom(health ~ age, data = data)
summary_model <- summary(model)
coefficients <- summary_model$coefficients
std_errors <- summary_model$standard.errors
z_values <- coefficients / std_errors
p_values <- 2 * (1 - pnorm(abs(z_values)))
return(list(p_values = as.vector(p_values), summary_model = summary_model))
}
# Setup parallel processing
cl <- makeCluster(detectCores() - 1)  # Use one less than the number of available cores
library(readr)
library(readtext)
library(SnowballC)
library(tidytext)
library(gamlr)
library(nnet)
library(dplyr)
library(glmnet)
library(ggplot2)
library(parallel)
library(doParallel)
data <- read_csv("training_set.csv")
# Identify and convert categorical variables (unique values < 20) to factors
for (var in names(data)) {
if (length(unique(data[[var]])) < 20) {
data[[var]] <- as.factor(data[[var]])
}
}
# Ensure the health column is a factor
data$health <- as.factor(data$health)
# Convert the age column to numeric
data$x633 <- as.numeric(data$x633)
# Define the response variable and the treatment
health <- data$health
age <- data$x633
# Plot the distribution of Age using a histogram
ggplot(data, aes(x = x633)) +
geom_histogram(binwidth = 5, fill = "blue", color = "black") +
xlab("Age") +
ylab("Count") +
ggtitle("Distribution of Respondents' Age") +
theme_minimal() +  # Apply a minimal theme for a cleaner look
theme(
plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
axis.title.x = element_text(size = 12, face = "bold"),
axis.title.y = element_text(size = 12, face = "bold")
)
# Function to perform multinomial logistic regression and return p-values
margreg <- function(i) {
model <- multinom(health ~ age, data = data)
summary_model <- summary(model)
coefficients <- summary_model$coefficients
std_errors <- summary_model$standard.errors
z_values <- coefficients / std_errors
p_values <- 2 * (1 - pnorm(abs(z_values)))
return(list(p_values = as.vector(p_values), summary_model = summary_model))
}
# Setup parallel processing
cl <- makeCluster(detectCores() - 1)  # Use one less than the number of available cores
clusterExport(cl, c("data", "health", "age", "margreg"))  # Export variables and functions to the cluster
clusterEvalQ(cl, {
library(nnet)
library(dplyr)
library(ggplot2)
})  # Ensure necessary libraries are loaded on each cluster
# Run the regression in parallel
P <- 1:10  # Dummy list to run the function multiple times
results <- parLapply(cl, P, function(x) margreg(x))
# Extract p-values and the summary model from one of the runs
mrgpvals_age <- unlist(lapply(results, function(res) res$p_values))
summary_model <- results[[1]]$summary_model
# Stop the cluster
stopCluster(cl)
# Plot the distribution of p-values
hist(mrgpvals_age, main="Distribution of P-values for age on Health", xlab="P-Value for age", ylab="Frequency", breaks = 100, xlim = c(0, 1))
# Print the summary model from one of the runs
print(summary_model)
# Select only the significant variables
significant_vars <- data[,c("x1", "x2", "x162", "x163", "x164", "x595", "x613", "x615", "x617", "x657", "x965", "x1179")]
# Prepare the data for LASSO regression using model.matrix to create dummy variables
predictors <- model.matrix(~ . - 1, data = significant_vars)
# Stage 1 LASSO: fit a model for age on other predictors using Gaussian family
model_age <- cv.glmnet(predictors, data$x633, alpha = 1, family = "gaussian")
# Predict age using the fitted LASSO model
dhat <- predict(model_age, s = "lambda.min", newx = predictors)
# Calculate the R-squared value
R2 <- cor(drop(dhat), data$x633)^2
cat("The In-Sample R-squared value is", R2, ".\n")
dhat <- as.numeric(dhat)
# Combine predicted age (dhat) with other predictors
predictors_combined <- cbind(dhat, significant_vars, age)
# Detect number of cores and register parallel backend
num_cores <- detectCores()
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Stage 2: Fit a multinomial logistic regression model using glmnet with parallel processing
model_health <- cv.glmnet(as.matrix(predictors_combined), as.matrix(data$health), family = "multinomial", alpha = 1, parallel = TRUE)
# Stop the cluster after model fitting
stopCluster(cl)
# Extract coefficients for the predicted age (dhat) for each class
coefficients_list <- coef(model_health, s = "lambda.min")
# Assuming we find the correct row name for dhat, extract and print the coefficient
for (i in 1:length(coefficients_list)) {
coef_matrix <- as.matrix(coefficients_list[[i]])
coef_value[i] <- coef_matrix["dhat", ]
cat("The effect of predicted age (dhat) on health status for class", i, "is", coef_value[i], ".\n")
}
# Combine predicted age with other predictors
predictors_combined2 <- cbind(significant_vars, age)
# Detect number of cores and register parallel backend
num_cores <- detectCores()
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Stage 2: Fit a multinomial logistic regression model using glmnet with parallel processing
model_health2 <- cv.glmnet(as.matrix(predictors_combined2), as.matrix(data$health), family = "multinomial", alpha = 1, parallel = TRUE)
# Stop the cluster after model fitting
stopCluster(cl)
# Extract coefficients for the predicted age for each class
coefficients_list2 <- coef(model_health2, s = "lambda.min")
# Assuming we find the correct row name for dhat, extract and print the coefficient
for (i in 1:length(coefficients_list2)) {
coef_matrix2 <- as.matrix(coefficients_list2[[i]])
coef_value2[i] <- coef_matrix2["age", ]
cat("The effect of d on health status from a naive lasso for class", i, "is", coef_value2[i], ".\n")
}
dhat <- as.numeric(dhat)
# Combine predicted age (dhat) with other predictors
predictors_combined <- cbind(dhat, significant_vars, age)
# Detect number of cores and register parallel backend
num_cores <- detectCores()
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Stage 2: Fit a multinomial logistic regression model using glmnet with parallel processing
model_health <- cv.glmnet(as.matrix(predictors_combined), as.matrix(data$health), family = "multinomial", alpha = 1, parallel = TRUE)
# Stop the cluster after model fitting
stopCluster(cl)
# Extract coefficients for the predicted age (dhat) for each class
coefficients_list <- coef(model_health, s = "lambda.min")
# Assuming we find the correct row name for dhat, extract and print the coefficient
for (i in 1:length(coefficients_list)) {
coef_matrix <- as.matrix(coefficients_list[[i]])
coef_value[i] <- coef_matrix["dhat", ]
cat("The effect of predicted age (dhat) on health status for class", i, "is", coef_value[i], ".\n")
}
library(readr)
library(readtext)
library(SnowballC)
library(tidytext)
library(gamlr)
library(nnet)
library(dplyr)
library(glmnet)
library(ggplot2)
library(parallel)
library(doParallel)
data <- read_csv("training_set.csv")
# Identify and convert categorical variables (unique values < 20) to factors
for (var in names(data)) {
if (length(unique(data[[var]])) < 20) {
data[[var]] <- as.factor(data[[var]])
}
}
# Ensure the health column is a factor
data$health <- as.factor(data$health)
# Convert the age column to numeric
data$x633 <- as.numeric(data$x633)
# Define the response variable and the treatment
health <- data$health
age <- data$x633
# Plot the distribution of Age using a histogram
ggplot(data, aes(x = x633)) +
geom_histogram(binwidth = 5, fill = "blue", color = "black") +
xlab("Age") +
ylab("Count") +
ggtitle("Distribution of Respondents' Age") +
theme_minimal() +  # Apply a minimal theme for a cleaner look
theme(
plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
axis.title.x = element_text(size = 12, face = "bold"),
axis.title.y = element_text(size = 12, face = "bold")
)
# Function to perform multinomial logistic regression and return p-values
margreg <- function(i) {
model <- multinom(health ~ age, data = data)
summary_model <- summary(model)
coefficients <- summary_model$coefficients
std_errors <- summary_model$standard.errors
z_values <- coefficients / std_errors
p_values <- 2 * (1 - pnorm(abs(z_values)))
return(list(p_values = as.vector(p_values), summary_model = summary_model))
}
# Setup parallel processing
cl <- makeCluster(detectCores() - 1)  # Use one less than the number of available cores
clusterExport(cl, c("data", "health", "age", "margreg"))  # Export variables and functions to the cluster
clusterEvalQ(cl, {
library(nnet)
library(dplyr)
library(ggplot2)
})  # Ensure necessary libraries are loaded on each cluster
# Run the regression in parallel
P <- 1:10  # Dummy list to run the function multiple times
results <- parLapply(cl, P, function(x) margreg(x))
# Extract p-values and the summary model from one of the runs
mrgpvals_age <- unlist(lapply(results, function(res) res$p_values))
summary_model <- results[[1]]$summary_model
# Stop the cluster
stopCluster(cl)
# Plot the distribution of p-values
hist(mrgpvals_age, main="Distribution of P-values for age on Health", xlab="P-Value for age", ylab="Frequency", breaks = 100, xlim = c(0, 1))
# Print the summary model from one of the runs
print(summary_model)
# Select only the significant variables
significant_vars <- data[,c("x1", "x2", "x162", "x163", "x164", "x595", "x613", "x615", "x617", "x657", "x965", "x1179")]
# Prepare the data for LASSO regression using model.matrix to create dummy variables
predictors <- model.matrix(~ . - 1, data = significant_vars)
# Stage 1 LASSO: fit a model for age on other predictors using Gaussian family
model_age <- cv.glmnet(predictors, data$x633, alpha = 1, family = "gaussian")
# Predict age using the fitted LASSO model
dhat <- predict(model_age, s = "lambda.min", newx = predictors)
# Calculate the R-squared value
R2 <- cor(drop(dhat), data$x633)^2
cat("The In-Sample R-squared value is", R2, ".\n")
dhat <- as.numeric(dhat)
# Combine predicted age (dhat) with other predictors
predictors_combined <- cbind(dhat, significant_vars, age)
# Detect number of cores and register parallel backend
num_cores <- detectCores()
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Stage 2: Fit a multinomial logistic regression model using glmnet with parallel processing
model_health <- cv.glmnet(as.matrix(predictors_combined), as.matrix(data$health), family = "multinomial", alpha = 1, parallel = TRUE)
# Stop the cluster after model fitting
stopCluster(cl)
# Extract coefficients for the predicted age (dhat) for each class
coefficients_list <- coef(model_health, s = "lambda.min")
# Assuming we find the correct row name for dhat, extract and print the coefficient
for (i in 1:length(coefficients_list)) {
coef_matrix <- as.matrix(coefficients_list[[i]])
coef_value[i] <- coef_matrix["dhat", ]
cat("The effect of predicted age (dhat) on health status for class", i, "is", coef_value[i], ".\n")
}
# Combine predicted age with other predictors
predictors_combined2 <- cbind(significant_vars, age)
# Detect number of cores and register parallel backend
num_cores <- detectCores()
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Stage 2: Fit a multinomial logistic regression model using glmnet with parallel processing
model_health2 <- cv.glmnet(as.matrix(predictors_combined2), as.matrix(data$health), family = "multinomial", alpha = 1, parallel = TRUE)
# Stop the cluster after model fitting
stopCluster(cl)
# Extract coefficients for the predicted age for each class
coefficients_list2 <- coef(model_health2, s = "lambda.min")
# Assuming we find the correct row name for dhat, extract and print the coefficient
for (i in 1:length(coefficients_list2)) {
coef_matrix2 <- as.matrix(coefficients_list2[[i]])
coef_value2[i] <- coef_matrix2["age", ]
cat("The effect of d on health status from a naive lasso for class", i, "is", coef_value2[i], ".\n")
}
library(readr)
library(readtext)
library(SnowballC)
library(tidytext)
library(gamlr)
library(nnet)
library(dplyr)
library(glmnet)
library(ggplot2)
library(parallel)
library(doParallel)
data <- read_csv("training_set.csv")
# Identify and convert categorical variables (unique values < 20) to factors
for (var in names(data)) {
if (length(unique(data[[var]])) < 20) {
data[[var]] <- as.factor(data[[var]])
}
}
# Ensure the health column is a factor
data$health <- as.factor(data$health)
# Convert the age column to numeric
data$x633 <- as.numeric(data$x633)
# Define the response variable and the treatment
health <- data$health
age <- data$x633
# Plot the distribution of Age using a histogram
ggplot(data, aes(x = x633)) +
geom_histogram(binwidth = 5, fill = "blue", color = "black") +
xlab("Age") +
ylab("Count") +
ggtitle("Distribution of Respondents' Age") +
theme_minimal() +  # Apply a minimal theme for a cleaner look
theme(
plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
axis.title.x = element_text(size = 12, face = "bold"),
axis.title.y = element_text(size = 12, face = "bold")
)
# Function to perform multinomial logistic regression and return p-values
margreg <- function(i) {
model <- multinom(health ~ age, data = data)
summary_model <- summary(model)
coefficients <- summary_model$coefficients
std_errors <- summary_model$standard.errors
z_values <- coefficients / std_errors
p_values <- 2 * (1 - pnorm(abs(z_values)))
return(list(p_values = as.vector(p_values), summary_model = summary_model))
}
# Setup parallel processing
cl <- makeCluster(detectCores() - 1)  # Use one less than the number of available cores
clusterExport(cl, c("data", "health", "age", "margreg"))  # Export variables and functions to the cluster
clusterEvalQ(cl, {
library(nnet)
library(dplyr)
library(ggplot2)
})  # Ensure necessary libraries are loaded on each cluster
# Run the regression in parallel
P <- 1:10  # Dummy list to run the function multiple times
results <- parLapply(cl, P, function(x) margreg(x))
# Extract p-values and the summary model from one of the runs
mrgpvals_age <- unlist(lapply(results, function(res) res$p_values))
summary_model <- results[[1]]$summary_model
# Stop the cluster
stopCluster(cl)
# Plot the distribution of p-values
hist(mrgpvals_age, main="Distribution of P-values for age on Health", xlab="P-Value for age", ylab="Frequency", breaks = 100, xlim = c(0, 1))
# Print the summary model from one of the runs
print(summary_model)
# Select only the significant variables
significant_vars <- data[,c("x1", "x2", "x162", "x163", "x164", "x595", "x613", "x615", "x617", "x657", "x965", "x1179")]
# Prepare the data for LASSO regression using model.matrix to create dummy variables
predictors <- model.matrix(~ . - 1, data = significant_vars)
# Stage 1 LASSO: fit a model for age on other predictors using Gaussian family
model_age <- cv.glmnet(predictors, data$x633, alpha = 1, family = "gaussian")
# Predict age using the fitted LASSO model
dhat <- predict(model_age, s = "lambda.min", newx = predictors)
# Calculate the R-squared value
R2 <- cor(drop(dhat), data$x633)^2
cat("The In-Sample R-squared value is", R2, ".\n")
# Causal LASSO
dhat <- as.numeric(dhat)
# Combine predicted age (dhat) with other predictors
predictors_combined <- cbind(dhat, significant_vars, age)
# Detect number of cores and register parallel backend
num_cores <- detectCores()
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Stage 2: Fit a multinomial logistic regression model using glmnet with parallel processing
model_health <- cv.glmnet(as.matrix(predictors_combined), as.matrix(data$health), family = "multinomial", alpha = 1, parallel = TRUE)
# Stop the cluster after model fitting
stopCluster(cl)
# Extract coefficients for the predicted age (dhat) for each class
coefficients_list <- coef(model_health, s = "lambda.min")
# Assuming we find the correct row name for dhat, extract and print the coefficient
for (i in 1:length(coefficients_list)) {
coef_matrix <- as.matrix(coefficients_list[[i]])
coef_value[i] <- coef_matrix["dhat", ]
cat("The effect of predicted age (dhat) on health status for class", i, "is", coef_value[i], ".\n")
}
# Naive LASSO
# Combine predicted age with other predictors
predictors_combined2 <- cbind(significant_vars, age)
# Detect number of cores and register parallel backend
num_cores <- detectCores()
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Stage 2: Fit a multinomial logistic regression model using glmnet with parallel processing
model_health2 <- cv.glmnet(as.matrix(predictors_combined2), as.matrix(data$health), family = "multinomial", alpha = 1, parallel = TRUE)
# Stop the cluster after model fitting
stopCluster(cl)
# Extract coefficients for the predicted age for each class
coefficients_list2 <- coef(model_health2, s = "lambda.min")
# Assuming we find the correct row name for dhat, extract and print the coefficient
for (i in 1:length(coefficients_list2)) {
coef_matrix2 <- as.matrix(coefficients_list2[[i]])
coef_value2[i] <- coef_matrix2["age", ]
cat("The effect of d on health status from a naive lasso for class", i, "is", coef_value2[i], ".\n")
}
library(readr)
library(readtext)
library(SnowballC)
library(tidytext)
library(gamlr)
library(nnet)
library(dplyr)
library(glmnet)
library(ggplot2)
library(parallel)
library(doParallel)
data <- read_csv("training_set.csv")
# Identify and convert categorical variables (unique values < 20) to factors
for (var in names(data)) {
if (length(unique(data[[var]])) < 20) {
data[[var]] <- as.factor(data[[var]])
}
}
# Ensure the health column is a factor
data$health <- as.factor(data$health)
# Convert the age column to numeric
data$x633 <- as.numeric(data$x633)
# Define the response variable and the treatment
health <- data$health
age <- data$x633
# Plot the distribution of Age using a histogram
ggplot(data, aes(x = x633)) +
geom_histogram(binwidth = 5, fill = "blue", color = "black") +
xlab("Age") +
ylab("Count") +
ggtitle("Distribution of Respondents' Age") +
theme_minimal() +  # Apply a minimal theme for a cleaner look
theme(
plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
axis.title.x = element_text(size = 12, face = "bold"),
axis.title.y = element_text(size = 12, face = "bold")
)
# Function to perform multinomial logistic regression and return p-values
margreg <- function(i) {
model <- multinom(health ~ age, data = data)
summary_model <- summary(model)
coefficients <- summary_model$coefficients
std_errors <- summary_model$standard.errors
z_values <- coefficients / std_errors
p_values <- 2 * (1 - pnorm(abs(z_values)))
return(list(p_values = as.vector(p_values), summary_model = summary_model))
}
# Setup parallel processing
cl <- makeCluster(detectCores() - 1)  # Use one less than the number of available cores
clusterExport(cl, c("data", "health", "age", "margreg"))  # Export variables and functions to the cluster
clusterEvalQ(cl, {
library(nnet)
library(dplyr)
library(ggplot2)
})  # Ensure necessary libraries are loaded on each cluster
# Run the regression in parallel
P <- 1:10  # Dummy list to run the function multiple times
results <- parLapply(cl, P, function(x) margreg(x))
# Extract p-values and the summary model from one of the runs
mrgpvals_age <- unlist(lapply(results, function(res) res$p_values))
summary_model <- results[[1]]$summary_model
# Stop the cluster
stopCluster(cl)
# Plot the distribution of p-values
hist(mrgpvals_age, main="Distribution of P-values for age on Health", xlab="P-Value for age", ylab="Frequency", breaks = 100, xlim = c(0, 1))
# Print the summary model from one of the runs
print(summary_model)
# Select only the significant variables
significant_vars <- data[,c("x1", "x2", "x162", "x163", "x164", "x595", "x613", "x615", "x617", "x657", "x965", "x1179")]
# Prepare the data for LASSO regression using model.matrix to create dummy variables
predictors <- model.matrix(~ . - 1, data = significant_vars)
# Stage 1 LASSO: fit a model for age on other predictors using Gaussian family
model_age <- cv.glmnet(predictors, data$x633, alpha = 1, family = "gaussian")
# Predict age using the fitted LASSO model
dhat <- predict(model_age, s = "lambda.min", newx = predictors)
# Calculate the R-squared value
R2 <- cor(drop(dhat), data$x633)^2
cat("The In-Sample R-squared value is", R2, ".\n")
dhat <- as.numeric(dhat)
# Combine predicted age (dhat) with other predictors
predictors_combined <- cbind(dhat, significant_vars, age)
# Detect number of cores and register parallel backend
num_cores <- detectCores()
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Stage 2: Fit a multinomial logistic regression model using glmnet with parallel processing
model_health <- cv.glmnet(as.matrix(predictors_combined), as.matrix(data$health), family = "multinomial", alpha = 1, parallel = TRUE)
# Stop the cluster after model fitting
stopCluster(cl)
# Extract coefficients for the predicted age (dhat) for each class
coefficients_list <- coef(model_health, s = "lambda.min")
coef_value <- numeric(length(coefficients_list))
# Assuming we find the correct row name for dhat, extract and print the coefficient
for (i in 1:length(coefficients_list)) {
coef_matrix <- as.matrix(coefficients_list[[i]])
coef_value[i] <- coef_matrix["dhat", ]
cat("The effect of predicted age (dhat) on health status for class", i, "is", coef_value[i], ".\n")
}
# Combine predicted age with other predictors
predictors_combined2 <- cbind(significant_vars, age)
# Detect number of cores and register parallel backend
num_cores <- detectCores()
cl <- makeCluster(num_cores)
registerDoParallel(cl)
# Stage 2: Fit a multinomial logistic regression model using glmnet with parallel processing
model_health2 <- cv.glmnet(as.matrix(predictors_combined2), as.matrix(data$health), family = "multinomial", alpha = 1, parallel = TRUE)
# Stop the cluster after model fitting
stopCluster(cl)
# Extract coefficients for the predicted age for each class
coefficients_list2 <- coef(model_health2, s = "lambda.min")
coef_value2 <- numeric(length(coefficients_list))
# Assuming we find the correct row name for dhat, extract and print the coefficient
for (i in 1:length(coefficients_list2)) {
coef_matrix2 <- as.matrix(coefficients_list2[[i]])
coef_value2[i] <- coef_matrix2["age", ]
cat("The effect of d on health status from a naive lasso for class", i, "is", coef_value2[i], ".\n")
}
