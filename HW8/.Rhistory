## actors network example
library(igraph)
### GRAPH
## read in a graph in the `graphml' format: xml for graphs.
## it warns about pre-specified ids, but we want this here
## (these ids match up with the castlists in movies.txt)
actnet <- read.graph("actors.graphml",format="graphml")
## actors network example
library(igraph)
### GRAPH
## read in a graph in the `graphml' format: xml for graphs.
## it warns about pre-specified ids, but we want this here
## (these ids match up with the castlists in movies.txt)
actnet <- read.graph("actors.graphml",format="graphml")
install.packages("textir", dependencies = TRUE)
install.packages("maptpx", dependencies = TRUE)
# Homework: congressional text dataset
# Much of this could have been copied straight from we8there.R or wine.R
# (that's why you had no starter script this week)
library(textir) # to get the data
library(maptpx) # for the topics function
data(congress109)
# [1] fit k-means for k in 5,10,15,20,25.  Use an IC to choose the
#   number of clusters and interpret some of the centers.
#  as we discussed in class, you can choose a variety of scales
#  upon which to fit k-means; here I just used standardized freq
fs <- scale(as.matrix( congress109Counts/rowSums(congress109Counts) ))
## follow wine code to fit for a set of k's
## notice the only difference here is that I've replaced 1:200 with 5*(1:5)
## the question asked for a smaller set of candidate models than we had for wine.
kfit <- lapply(5*(1:5), function(k) kmeans(fs,k))
source("kIC.R")
fx <- read.csv("FXmonthly.csv")
setwd("/Users/yiningqu/Desktop/研究生/Big data/HW8")
fx <- read.csv("FXmonthly.csv")
fx <- (fx[2:120,]-fx[1:119,])/(fx[1:119,])
library(stats)
library(glmnet)
install.packages("glmnet")
library(stats)
library(glmnet)
library(Rcpp)
library(ggplot2)
library(reshape2)
install.packages("reshape2")
library(stats) install.packages("glmnet"
library(stats)
library(glmnet)
library(Rcpp)
library(ggplot2)
library(reshape2)
fx <- read.csv("FXmonthly.csv")
fx <- (fx[2:120,]-fx[1:119,])/(fx[1:119,])
fx <- read.csv("FXmonthly.csv")
fx <- (fx[2:120,]-fx[1:119,])/(fx[1:119,])
sp500 <- read_csv("sp500.csv")
fx <- read.csv("FXmonthly.csv")
fx <- (fx[2:120,]-fx[1:119,])/(fx[1:119,])
sp500 <- read.csv("sp500.csv")
# Calculate and visualize the correlation matrix
cor_matrix <- cor(fx)
corrplot::corrplot(cor_matrix, method = "circle")
library(stats)
library(glmnet)
library(Rcpp)
library(ggplot2)
library(reshape2)
library(corrplot)
install.packages("corrplot")
library(stats)
library(glmnet)
library(Rcpp)
library(ggplot2)
library(reshape2)
library(corrplot)
fx <- read.csv("FXmonthly.csv")
fx <- (fx[2:120,]-fx[1:119,])/(fx[1:119,])
sp500 <- read.csv("sp500.csv")
# Calculate and visualize the correlation matrix
cor_matrix <- cor(fx)
corrplot::corrplot(cor_matrix, method = "circle")
library(stats)
library(glmnet)
library(Rcpp)
library(ggplot2)
library(reshape2)
print(cor_matrix)
print(cor_matrix)
# Fit PCA
pcfx <- prcomp(fx)
# Plotting the variance explained by each principal component
plot(pcfx, type = "lines")
# Scree plot to decide on the number of components
fviz_eig(pcfx)
# Fit PCA
pcfx <- prcomp(fx)
PEVs<-pcfx$sdev^2 # these are the PEV's
total<-sum(PEVs)
barplot(PEVs/total)
# Fit PCA
pcfx <- prcomp(fx, scale = TRUE)
# this is called a Scree plot, you can also obtain it by plotting cummulative PEV values
PEVs<-pcfx$sdev^2 # these are the PEV's
total<-sum(PEVs)
barplot(PEVs/total)
# Fit PCA
pcfx <- prcomp(fx, scale = TRUE)
plot(pcfx, main="")
zfx <- predict(pcfx)
par(mfrow=c(1,2))
plot(zfx[,1:2], type="n", xlim=c(-4,5))
text(x=zfx[,1], y=zfx[,2], labels=rownames(zfx), col="blue")
plot(zfx[,3:4], type="n", xlim=c(-3,3))
text(x=zfx[,3], y=zfx[,4], labels=rownames(zfx), col="blue")
# Fit PCA
pcfx <- prcomp(fx, scale = TRUE)
plot(pcfx, main="")
zfx <- predict(pcfx)
par(mfrow=c(1,2))
plot(zfx[,1:2], type="n", xlim=c(-4,5))
text(x=zfx[,1], y=zfx[,2], labels=rownames(zfx), col="blue")
plot(zfx[,3:4], type="n", xlim=c(-3,3))
text(x=zfx[,3], y=zfx[,4], labels=rownames(zfx), col="blue")
pcs <- predict(pcfx)
plot(pcs[,1], pcs[,2], xlab = "First Principal Component", ylab = "Second Principal Component", main = "Scatter Plot of the First Two Principal Components", pch = 20, col = 'blue')
text(pcs[,1], pcs[,2], labels = rownames(pcs), pos = 4, cex = 0.6)
plot(pcs[,2], pcs[,3], xlab = "Second Principal Component", ylab = "Third Principal Component", main = "Scatter Plot of the Second versus the Third Principal Components", pch = 20, col = 'blue')
text(pcs[,1], pcs[,2], labels = rownames(pcs), pos = 4, cex = 0.6)
sort(pcs[,1])
# far right
smallest_pcs <- sort(pcs[,1])[1:5]
smallest_pcs
# far left
largest_pcs <- sort(pcs[,1], decreasing = TRUE)[1:5]
largest_pcs
library(stats)
library(glmnet)
library(Rcpp)
library(ggplot2)
library(reshape2)
library(corrplot)
fx <- read.csv("FXmonthly.csv")
fx <- (fx[2:120,]-fx[1:119,])/(fx[1:119,])
sp500 <- read.csv("sp500.csv")
# Calculate and visualize the correlation matrix
cor_matrix <- cor(fx)
corrplot::corrplot(cor_matrix, method = "circle")
print(cor_matrix)
View(fx)
# Fit PCA
pcfx <- prcomp(fx, scale = TRUE)
plot(pcfx, main="")
pcs <- predict(pcfx)
plot(pcs[,1], pcs[,2], xlab = "First Principal Component", ylab = "Second Principal Component", main = "Scatter Plot of the First Two Principal Components", pch = 20, col = 'blue')
text(pcs[,1], pcs[,2], labels = rownames(pcs), pos = 4, cex = 0.6)
plot(pcs[,2], pcs[,3], xlab = "Second Principal Component", ylab = "Third Principal Component", main = "Scatter Plot of the Second versus the Third Principal Components", pch = 20, col = 'blue')
text(pcs[,1], pcs[,2], labels = rownames(pcs), pos = 4, cex = 0.6)
# far right
smallest_pcs <- sort(pcs[,1])[1:5]
smallest_pcs
# far left
largest_pcs <- sort(pcs[,1], decreasing = TRUE)[1:5]
largest_pcs
t(round(pcfx$rotation[,1:2],2))
# Choose the number of principal components to keep (let's say K)
K <- 2  # Hypothetical choice based on the scree plot above
fx_pca_scores <- data.frame(pcfx$x[, 1:K])
# Linear regression using the first K principal components
linear_model <- lm(sp500 ~ fx_pca_scores)
### Principal components regression
# to get AICc, plus we'll do lasso below
## convert to a data frame so glm can keep track of names
zdf <- as.data.frame(pcs)
## do regression onto the first two
summary(fxglm <- glm(sp500$sp500 ~ ., data=zdf[,1:2]))
## Get glm fits on 1:20 factors
kfits <- lapply(1:20,
function(K) glm(sp500$sp500~., data=zdf[,1:K,drop=FALSE]))
aicc <- sapply(kfits, AICc) # apply AICc to each fit
View(kfit)
# Convert the principal components to a data frame for modeling
zdf <- as.data.frame(pcs)
# Perform regression using the first two principal components
summary(fxglm <- glm(sp500$sp500 ~ ., data=zdf[, 1:2]))
# Function to calculate AICc for a glm model
calculateAICc <- function(model) {
AICc(model)
}
# Perform GLM fits on 1:20 factors and calculate AICc for each
kfits <- lapply(1:20, function(K) {
glm(sp500$sp500 ~ ., data = zdf[, 1:K, drop = FALSE])
})
aicc <- sapply(kfits, calculateAICc) # Apply AICc calculation to each fit
if (!requireNamespace("AICcmodavg", quietly = TRUE)) {
install.packages("AICcmodavg")
}
# Load the AICcmodavg package
library(AICcmodavg)
# Convert the principal components to a data frame for modeling
zdf <- as.data.frame(pcs)
# Perform regression using the first two principal components
summary(fxglm <- glm(sp500$sp500 ~ ., data=zdf[, 1:2]))
# Function to calculate AICc for a glm model
calculateAICc <- function(model) {
AICc(model)
}
# Perform GLM fits on 1:20 factors and calculate AICc for each
kfits <- lapply(1:20, function(K) {
glm(sp500$sp500 ~ ., data = zdf[, 1:K, drop = FALSE])
})
aicc <- sapply(kfits, calculateAICc) # Apply AICc calculation to each fit
which.min(aicc) # Determine which model size (number of factors) is preferred by AICc
# Optionally, also calculate BIC for comparison
bic <- sapply(kfits, BIC)
which.min(bic) # Determine which model size (number of factors) is preferred by BIC
# Plot the AICc values
plot(aicc, type = 'b', xlab = "Number of Factors", ylab = "AICc", main = "AICc by Number of Factors")
View(sp500)
if (!requireNamespace("AICcmodavg", quietly = TRUE)) {
install.packages("AICcmodavg")
}
# Load the AICcmodavg package
library(AICcmodavg)
# Convert the principal components to a data frame for modeling
zdf <- as.data.frame(pcs)
# Perform regression using the first two principal components
summary(fxglm <- glm(sp500$sp500 ~ ., data=zdf[, 1:2]))
# Function to calculate AICc for a glm model
calculateAICc <- function(model) {
AICc(model)
}
# Perform GLM fits on 1:20 factors and calculate AICc for each
kfits <- lapply(1:20, function(K) {
glm(sp500$sp500 ~ ., data = zdf[, 1:K, drop = FALSE])
})
aicc <- sapply(kfits, calculateAICc) # Apply AICc calculation to each fit
which.min(aicc) # Determine which model size (number of factors) is preferred by AICc
# Optionally, also calculate BIC for comparison
bic <- sapply(kfits, BIC)
which.min(bic) # Determine which model size (number of factors) is preferred by BIC
# Plot the AICc values
plot(aicc, type = 'b', xlab = "Number of Factors", ylab = "AICc", main = "AICc by Number of Factors")
View(calculateAICc)
View(kfit)
best_K <- which.min(aicc)
print(coef(kfits[[best_K]]))
best_aicc_index <- which.min(aicc)
print(coef(kfits[[best_aicc_index]]))
best_bic_index <- which.min(bic)
print(coef(kfits[[best_bic_index]]))
set.seed(4)
if (!requireNamespace("AICcmodavg", quietly = TRUE)) {
install.packages("AICcmodavg")
}
# Load the AICcmodavg package
library(AICcmodavg)
# Convert the principal components to a data frame for modeling
zdf <- as.data.frame(pcs)
# Perform regression using the first two principal components
summary(fxglm <- glm(sp500$sp500 ~ ., data=zdf[, 1:2]))
# Function to calculate AICc for a glm model
calculateAICc <- function(model) {
AICc(model)
}
# Perform GLM fits on 1:20 factors and calculate AICc for each
kfits <- lapply(1:20, function(K) {
glm(sp500$sp500 ~ ., data = zdf[, 1:K, drop = FALSE])
})
aicc <- sapply(kfits, calculateAICc) # Apply AICc calculation to each fit
which.min(aicc) # Determine which model size (number of factors) is preferred by AICc
# Optionally, also calculate BIC for comparison
bic <- sapply(kfits, BIC)
which.min(bic) # Determine which model size (number of factors) is preferred by BIC
# Plot the AICc values
plot(aicc, type = 'b', xlab = "Number of Factors", ylab = "AICc", main = "AICc by Number of Factors")
best_aicc_index <- which.min(aicc)
print(coef(kfits[[best_aicc_index]]))
set.seed(4)
if (!requireNamespace("AICcmodavg", quietly = TRUE)) {
install.packages("AICcmodavg")
}
# Load the AICcmodavg package
library(AICcmodavg)
# Convert the principal components to a data frame for modeling
zdf <- as.data.frame(pcs)
# Perform regression using the first two principal components
summary(fxglm <- glm(sp500$sp500 ~ ., data=zdf[, 1:2]))
# Function to calculate AICc for a glm model
calculateAICc <- function(model) {
AICc(model)
}
# Perform GLM fits on 1:8 factors and calculate AICc for each
kfits <- lapply(1:8, function(K) {
glm(sp500$sp500 ~ ., data = zdf[, 1:K, drop = FALSE])
})
aicc <- sapply(kfits, calculateAICc) # Apply AICc calculation to each fit
which.min(aicc) # Determine which model size (number of factors) is preferred by AICc
# Optionally, also calculate BIC for comparison
bic <- sapply(kfits, BIC)
which.min(bic) # Determine which model size (number of factors) is preferred by BIC
# Plot the AICc values
plot(aicc, type = 'b', xlab = "Number of Factors", ylab = "AICc", main = "AICc by Number of Factors")
best_aicc_index <- which.min(aicc)
print(coef(kfits[[best_aicc_index]]))
lassoPCR <- cv.gamlr(x=pcs, y=sp500$sp500, nfold=20)
library(stats)
library(glmnet)
library(Rcpp)
library(ggplot2)
library(reshape2)
library(corrplot)
lassoPCR <- cv.gamlr(x=pcs, y=sp500$sp500, nfold=20)
# Ensure the glmnet package is installed and loaded
if (!requireNamespace("glmnet", quietly = TRUE)) {
install.packages("glmnet")
}
library(glmnet)
# Assuming 'pcs' is a data frame or matrix of principal components
# and 'sp500$sp500' is a vector of your response variable
# Convert 'pcs' to matrix if it is not already
pcs_matrix <- as.matrix(pcs)
# Set seed for reproducibility
set.seed(4)
# Perform Lasso regression with cross-validation
lassoPCR <- cv.glmnet(x = pcs_matrix, y = sp500$sp500, family = "gaussian", nfolds = 20, alpha = 1)
# Coefficients at the best lambda (lambda that gives minimum mean cross-validated error)
lasso_coef <- coef(lassoPCR, s = "lambda.min")
# Plotting the results
par(mfrow=c(1,2))  # Set up the plotting area to have 1 row and 2 columns
# Plot AICc
plot(aicc, pch=21, bg="maroon", xlab="K", ylab="AICc", main="AICc by Number of Factors")
# Plot Lasso path
plot(lassoPCR)
title("Lasso Path")
lambda_min <- lassoPCR$lambda.min
lasso_model_min <- glmnet(z_matrix, sp500$sp500, lambda = lambda_min)
lambda_min <- lassoPCR$lambda.min
lasso_model_min <- glmnet(pcs_matrix, sp500$sp500, lambda = lambda_min)
coefficients_min <- coef(lassoPCR, s = "lambda.min")
print(coefficients_min)
# Assuming `pcs` are your principal components and `sp500$sp500` your response variable
# GLM for optimal K using AIC/BIC
aic_values <- sapply(1:20, function(K) {
model <- glm(sp500$sp500 ~ ., data = as.data.frame(pcs[, 1:K]))
AIC(model)
})
optimal_k <- which.min(aic_values)
glm_best <- glm(sp500$sp500 ~ ., data = as.data.frame(pcs[, 1:optimal_k]))
# Lasso across all components
lasso_model <- cv.glmnet(x = as.matrix(pcs), y = sp500$sp500, alpha = 1)
plot(lasso_model)
best_lambda <- lasso_model$lambda.min
lasso_coefs <- coef(lasso_model, s = best_lambda)
# Compare and interpret results
cat("GLM Best Model Coefficients:\n")
print(coef(glm_best))
cat("\nLasso Model Coefficients at best lambda:\n")
print(lasso_coefs)
# Assuming `pcs` are your principal components and `sp500$sp500` your response variable
set.seed(4)
# GLM for optimal K using AIC/BIC
aic_values <- sapply(1:20, function(K) {
model <- glm(sp500$sp500 ~ ., data = as.data.frame(pcs[, 1:K]))
AIC(model)
})
optimal_k <- which.min(aic_values)
glm_best <- glm(sp500$sp500 ~ ., data = as.data.frame(pcs[, 1:optimal_k]))
# Lasso across all components
lasso_model <- cv.glmnet(x = as.matrix(pcs), y = sp500$sp500, alpha = 1)
plot(lasso_model)
best_lambda <- lasso_model$lambda.min
lasso_coefs <- coef(lasso_model, s = best_lambda)
# Compare and interpret results
cat("GLM Best Model Coefficients:\n")
print(coef(glm_best))
cat("\nLasso Model Coefficients at best lambda:\n")
print(lasso_coefs)
# Assuming `pcs` are your principal components and `sp500$sp500` your response variable
set.seed(4)
# GLM for optimal K using AIC/BIC
aic_values <- sapply(1:20, function(K) {
model <- glm(sp500$sp500 ~ ., data = as.data.frame(pcs[, 1:K]))
AIC(model)
})
optimal_k <- which.min(aic_values)
glm_best <- glm(sp500$sp500 ~ ., data = as.data.frame(pcs[, 1:optimal_k]))
# Lasso across all components
lasso_model <- cv.glmnet(x = as.matrix(pcs), y = sp500$sp500, alpha = 1)
best_lambda <- lasso_model$lambda.min
lasso_coefs <- coef(lasso_model, s = best_lambda)
# Compare and interpret results
cat("GLM Best Model Coefficients:\n")
print(coef(glm_best))
cat("\nLasso Model Coefficients at best lambda:\n")
print(lasso_coefs)
plot(lasso_model)
# Prepare the data
fx_matrix <- as.matrix(fx)  # Convert fx to matrix if not already
sp500_vector <- sp500$sp500  # Assuming sp500$sp500 is already a vector
# Fit Lasso model using cross-validation to determine the best lambda
set.seed(4)  # For reproducibility
cv_lasso_fx <- cv.glmnet(x = fx_matrix, y = sp500_vector, alpha = 1, family = "gaussian", nfolds = 10)
# Coefficients at the best lambda
best_lambda_fx <- cv_lasso_fx$lambda.min
coefficients_fx <- coef(cv_lasso_fx, s = "lambda.min")
# Print the coefficients
print(coefficients_fx)
# Plot the Lasso path
plot(cv_lasso_fx)
title("Lasso Path for Original Covariates")
# Prepare the data
fx_matrix <- as.matrix(fx)  # Convert fx to matrix if not already
sp500_vector <- sp500$sp500  # Assuming sp500$sp500 is already a vector
# Fit Lasso model using cross-validation to determine the best lambda
set.seed(4)  # For reproducibility
cv_lasso_fx <- cv.glmnet(x = fx_matrix, y = sp500_vector, alpha = 1, family = "gaussian", lambda = 10^seq(3, -2, by = -0.1))
# Coefficients at the best lambda
best_lambda_fx <- cv_lasso_fx$lambda.min
coefficients_fx <- coef(cv_lasso_fx, s = "lambda.min")
# Print the coefficients
print(coefficients_fx)
# Plot the Lasso path
plot(cv_lasso_fx)
title("Lasso Path for Original Covariates")
# Prepare the data
fx_matrix <- as.matrix(fx)  # Convert fx to matrix if not already
sp500_vector <- sp500$sp500  # Assuming sp500$sp500 is already a vector
# Fit Lasso model using cross-validation to determine the best lambda
set.seed(4)  # For reproducibility
cv_lasso_fx <- cv.glmnet(x = fx_matrix, y = sp500_vector, alpha = 1, family = "gaussian", nfolds = 10)
# Coefficients at the best lambda
best_lambda_fx <- cv_lasso_fx$lambda.min
coefficients_fx <- coef(cv_lasso_fx, s = "lambda.min")
# Print the coefficients
print(coefficients_fx)
# Plot the Lasso path
plot(cv_lasso_fx)
title("Lasso Path for Original Covariates")
# Prepare the data
fx_matrix <- as.matrix(fx)  # Convert fx to matrix if not already
sp500_vector <- sp500$sp500  # Assuming sp500$sp500 is already a vector
# Fit Lasso model using cross-validation to determine the best lambda
set.seed(41201)  # For reproducibility
cv_lasso_fx <- cv.glmnet(x = fx_matrix, y = sp500_vector, alpha = 1, family = "gaussian", nfolds = 10)
# Coefficients at the best lambda
best_lambda_fx <- cv_lasso_fx$lambda.min
coefficients_fx <- coef(cv_lasso_fx, s = "lambda.min")
# Print the coefficients
print(coefficients_fx)
# Plot the Lasso path
plot(cv_lasso_fx)
title("Lasso Path for Original Covariates")
# Prepare the data
fx_matrix <- as.matrix(fx)  # Convert fx to matrix if not already
sp500_vector <- sp500$sp500  # Assuming sp500$sp500 is already a vector
# Fit Lasso model using cross-validation to determine the best lambda
set.seed(41201)  # For reproducibility
lambda_values <- 10^seq(3, -2, by = -0.1)
cv_lasso_fx <- cv.glmnet(x = fx_matrix, y = sp500_vector, alpha = 1, family = "gaussian", lambda = lambda_values )
# Coefficients at the best lambda
best_lambda_fx <- cv_lasso_fx$lambda.min
coefficients_fx <- coef(cv_lasso_fx, s = "lambda.min")
# Print the coefficients
print(coefficients_fx)
# Plot the Lasso path
plot(cv_lasso_fx)
title("Lasso Path for Original Covariates")
# Prepare the data
fx_matrix <- as.matrix(fx)  # Convert fx to matrix if not already
sp500_vector <- sp500$sp500  # Assuming sp500$sp500 is already a vector
# Fit Lasso model using cross-validation to determine the best lambda
set.seed(41201)  # For reproducibility
lambda_values <- 10^seq(3, -2, by = -0.1)
cv_lasso_fx <- cv.glmnet(x = fx_matrix, y = sp500_vector, family = "gaussian", lambda = lambda_values )
# Coefficients at the best lambda
best_lambda_fx <- cv_lasso_fx$lambda.min
coefficients_fx <- coef(cv_lasso_fx, s = "lambda.min")
# Print the coefficients
print(coefficients_fx)
# Plot the Lasso path
plot(cv_lasso_fx)
title("Lasso Path for Original Covariates")
# Prepare the data
fx_matrix <- as.matrix(fx)  # Convert fx to matrix if not already
sp500_vector <- sp500$sp500  # Assuming sp500$sp500 is already a vector
# Fit Lasso model using cross-validation to determine the best lambda
set.seed(41201)  # For reproducibility
lambda_values <- 10^seq(3, -2, by = -0.1)
cv_lasso_fx <- cv.glmnet(x = fx_matrix, y = sp500_vector, alpha = 1, family = "gaussian", lambda = lambda_values )
# Coefficients at the best lambda
best_lambda_fx <- cv_lasso_fx$lambda.min
coefficients_fx <- coef(cv_lasso_fx, s = "lambda.min")
# Print the coefficients
print(coefficients_fx)
# Plot the Lasso path
plot(cv_lasso_fx)
title("Lasso Path for Original Covariates")
# Prepare the data
fx_matrix <- as.matrix(fx)  # Convert fx to matrix if not already
sp500_vector <- sp500$sp500  # Assuming sp500$sp500 is already a vector
# Fit Lasso model using cross-validation to determine the best lambda
set.seed(41201)  # For reproducibility
lambda_values <- 10^seq(3, -2, by = -0.1)
cv_lasso_fx <- cv.glmnet(x = fx_matrix, y = sp500_vector, alpha = 1, family = "gaussian", nfolds = 20)
# Coefficients at the best lambda
best_lambda_fx <- cv_lasso_fx$lambda.min
coefficients_fx <- coef(cv_lasso_fx, s = "lambda.min")
# Print the coefficients
print(coefficients_fx)
# Plot the Lasso path
plot(cv_lasso_fx)
title("Lasso Path for Original Covariates")
